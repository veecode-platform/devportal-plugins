# Kubernetes Plugins and extensions

This repo contains a few Backstage plugins and plugin extensions for Kubernetes-related funcionalities. It also contains a Backstage hosting application ("app" and "backend" packages) to host and test those plugins.

This document also helps you start a local temporary Kubernetes cluster to test the plugin connection against it in several scenarios.

You can also build a dynamic version of this module and test its behavior as a dynamic plugin without the need to push it into NPM. Check the [DYNAMIC.md](./dynamic/DYNAMIC.md) file for more information.

## Custom Secret Auth Module (Kubernetes Plugin Extension)

This project contains a plugin for a custom [Backstage](https://backstage.io) Kubernetes authentication module and a hosting app to run it.

The module provides an alternate Kubernetes authentication module that extends the regular Kubernetes `serviceAccount` token connection method, by allowing its value to be fetched in runtime in several ways.

- `secret`: fetches the token from a Kubernetes secret
- `env`: fetches the token from an environment variable
- `file`: fetches the token from a file

## Custom Catalog Locator (Kubernetes Plugin Extension)

The project includes an enhanced catalog-based cluster discovery system that extends the default Backstage Kubernetes plugin with additional capabilities:

- **Catalog-Driven Clusters**: Define Kubernetes clusters entirely through catalog entities without app-config changes
- **Flexible Authentication**: Fetch service account tokens from Kubernetes secrets, environment variables, or files at runtime
- **Cluster Enhancement**: Automatically enrich clusters with default values and custom metadata
- **Unified View**: Seamlessly merge catalog-based clusters with traditional config-based clusters

This allows organizations to manage Kubernetes cluster definitions through the catalog while maintaining secure token management outside of configuration files.

### What is hard to understand

When using the `secret` source, this plugin will fetch secrets from a cluster in runtime (usually the one itself is running), in order to get a serviceAccount token to authenticate against **another cluster** (the one listed in `app-config.yaml`).

When developing this plugin locally (so, not in a cluster), fetching the secret will transparently fallback to your current active kube config (the local `vkdr` cluster if you follow the steps in the quick start). It just happens to be the same targeted cluster, but by all means please understand the target cluster could be any cluster anywhere.

## Quick start (hosting app)

This hosting app helps plugin development, but it requires some extra setup for the testing scenarios:

- a local cluster (started using `vkdr`)
- a temporary token (also generated by `vkdr`)
- some labeled deployments (`vkdr` helps on this too)

To start a local temporary Kubernetes cluster we will use our [vkdr](https://docs.platform.vee.codes/vkdr/intro) tool:

```sh
vkdr infra start --api-port 9000
```

Install a couple of annotated services in the cluster (so they available in the cluster view):

```sh
vkdr kong install --default-ic --label=vee.codes/cluster=vkdr-config-cluster
vkdr whoami install --label=vee.codes/cluster=vkdr-catalog-cluster
```

Obtain both a service account token from the cluster and the cluster's CA data:

```sh
export K8S_SA_TOKEN=$(vkdr infra createToken --silent)
export K8S_CA_DATA=$(vkdr infra getca --silent)
```

Create a secret in the cluster to store the service account token:

```sh
kubectl create secret generic mysecret --from-literal=token=${K8S_SA_TOKEN}
```

In this scenario we will use the service account token to authenticate against the same cluster in two different ways:

- `vkdr-config-cluster`: using the service account token as a static config (the regular way of the kubernetes backend plugin)
- `vkdr-catalog-cluster`: using the service account token as a secret (using the secret auth module created by this project)

Notice both static configs for the local cluster in the `app-config.yaml` file (it looks like as if there are two clusters):

```yaml
kubernetes:
  serviceLocatorMethod:
    type: 'singleTenant'
  clusterLocatorMethods:
    - type: 'config'
      clusters:
        - name: vkdr-config-cluster
          url: https://127.0.0.1:9000
          authProvider: 'serviceAccount'
          skipTLSVerify: false
          caData: ${K8S_CA_DATA}
          serviceAccountToken: ${K8S_SA_TOKEN}
        - name: vkdr-catalog-cluster
          url: https://127.0.0.1:9000
          authProvider: 'serviceAccount'
          skipTLSVerify: false
          caData: ${K8S_CA_DATA}
          authMetadata:
            secretName: "mysecret"
            # source: secret (k8s secret), env (env var), file (file)
            source: secret
            namespace: default
```

To start the Backstage hosting app, run:

```sh
yarn install
yarn start
```

## Publishing a Release

### Set release version

Define the release version editing the Makefile itself (KUBERNETES_VERSION variable) and call:

```sh
make set-version
```

Or just bump it (it will do `set-version` too):

```sh
make bump-version
```

### Publish Static plugin

Just run the `publish` task to release the static plugin:

```sh
make publish
```

You can test this against a local registry (like Verdaccio):

```sh
make publish NPM_REGISTRY=http://localhost:4873
```

### Publish Dynamic plugin

Just run the `publish` task to release the static plugin:

```sh
make publish-dynamic
```

You can test this against a local registry (like Verdaccio):

```sh
make publish-dynamic NPM_REGISTRY=http://localhost:4873
```
